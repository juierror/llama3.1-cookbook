{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d9da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade transformers datasets bitsandbytes peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "861b446c-1c09-4ba8-a1f2-6ca45205c76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BitsAndBytesConfig, LlamaForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "from peft import LoraConfig\n",
    "import torch\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a87560-1d0a-426a-80d8-fcfcb8bd461f",
   "metadata": {},
   "source": [
    "# Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31b29ed-2a14-4c25-a048-b8975caa45ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52332689-ca06-4117-93d1-56ba21af1a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327de6da304b4a408ace7a5c10cfa121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e451cc57-4a22-4cc2-bd49-d1e72aac049f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5591548160"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_memory_footprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bfb2289-5723-45b2-a9c6-0e13fbcfb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddb9b3fa-59fd-413a-932e-0fb557718e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b8a71d-0fa3-4506-9b6a-3efc162ec134",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6f93b8e-bfab-4689-870c-4ad989e210d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare table for cosql and sparc\n",
    "with open(\"./data/cosql_dataset/tables.json\") as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    \n",
    "database = dict()\n",
    "\n",
    "for db in json_data:\n",
    "    database[db[\"db_id\"]] = dict()\n",
    "    for table in db[\"table_names_original\"]:\n",
    "        database[db[\"db_id\"]][table] = []\n",
    "    for column in db[\"column_names_original\"]:\n",
    "        table_id = column[0]\n",
    "        col_name = column[1]\n",
    "        if table_id != -1:\n",
    "            database[db[\"db_id\"]][db[\"table_names_original\"][table_id]].append(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce7dceb8-97ac-43bb-b188-18de6dda52ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "spider = load_dataset(\"spider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b587ec-5228-4050-84bb-f7542efa7a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['db_id', 'query', 'question', 'query_toks', 'query_toks_no_value', 'question_toks'],\n",
       "        num_rows: 7000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['db_id', 'query', 'question', 'query_toks', 'query_toks_no_value', 'question_toks'],\n",
       "        num_rows: 1034\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "755a46c2-18f0-447c-8eb8-c5a8f2633a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_id_to_table(db_id):\n",
    "    global database\n",
    "    db = database[db_id]\n",
    "    table = [f\"table:{table}\\ntable_column: {','.join(db[table])}\\n\" for table in db]\n",
    "    table = \"---\\n\".join(table)\n",
    "    table += \"---\\n\"\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eae62ab-3bd9-4325-874a-3c1b3a3b0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(\"\\xa0\", \" \").strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def clean_query(query):\n",
    "    query = clean_text(query).replace(\" , \", \", \")\n",
    "    if query[-1] == \";\":\n",
    "        query = query[:-1]\n",
    "    return query\n",
    "\n",
    "def get_prompt(tables, question):\n",
    "    question = clean_text(question)\n",
    "    prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are SQL expert. The user will give you a database table information and question in this form\n",
    "\n",
    "table: table_name_1\n",
    "table_column: column_1,column_2,column_3\n",
    "---\n",
    "table: table_name_2\n",
    "table_column: column_1,column_2\n",
    "---\n",
    "question: user question\n",
    "\n",
    "You have to answer valid SQL query.\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>{tables}question:{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27ed5464-9297-4825-aa32-2c7815cc8cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider_preprocess_function(examples):\n",
    "    tables = db_id_to_table(examples[\"db_id\"])\n",
    "    examples[\"query\"] = clean_query(examples[\"query\"])\n",
    "    examples[\"prompt\"] = get_prompt(tables, examples[\"question\"])\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4fb8a7b-e118-4835-9828-2a48c612f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_train = spider[\"train\"].map(spider_preprocess_function, remove_columns=['db_id', 'question', 'query_toks', 'query_toks_no_value', 'question_toks'])\n",
    "spider_val = spider[\"validation\"].map(spider_preprocess_function, remove_columns=['db_id', 'question', 'query_toks', 'query_toks_no_value', 'question_toks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7d74429-6e40-44ca-bffc-25a1068843d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider_tokenize(examples):\n",
    "    return tokenizer(examples[\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34888a6a-6959-4cd2-8c4a-42ca75d93792",
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_train = spider_train.map(spider_tokenize, remove_columns=['prompt', 'query'])\n",
    "spider_val = spider_val.map(spider_tokenize, remove_columns=['prompt', 'query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972cff1b-59a7-4648-b2c7-0fa12082987b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecac2227-ac82-4f2b-9443-c0d64c4d53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bd3fd06-e330-4da1-b009-f8b03f23c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # freeze the model - train adapters later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1b17692-0b72-408d-a592-2cc86c50c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.01,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model.add_adapter(peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4439c4b-fc89-4629-9ced-f8d36b47ccf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 44040192 || all params: 4584640512 || trainable%: 0.9606029498872953\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ecbaaec-eb7f-4c62-8f44-afd30d2f2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=\"outputs\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=32,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=2,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    bf16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cdbf0d0-0ce6-4809-83f0-7fba827fd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=spider_train,\n",
    "    eval_dataset=spider_val,\n",
    "    args=train_args,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c173a0-8817-446c-bf41-5a54b564f3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
